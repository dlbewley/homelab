:toc:
:icons: font
:sectanchors:
:sectlinks:
:toc: []

= Tools to Help with My Home Lab Setup

.**Secrets**
[TIP]
I am using https://keybase.io/[Keybase.io] to hold my secrets, becuase it's slightly simpler than https://docs.ansible.com/ansible/latest/user_guide/vault.html[Ansible vault] and I don't have anything fancy like https://www.vaultproject.io/[Hashi Vault] at this time.

.**Red Hat Subscriptions**
[TIP]
====
To use Red Hat subscriptions:

* Create an activation key for the _Employee SKU_ subscription in https://access.redhat.com/management/activation_keys[the portal].
* Create an ansible vars file in keybase kinda like the following to be used by link:tasks/RedHat-pre-tasks.yml[]

[source,yaml]
----
rhn_org_id: "99999999"
rhn_activation_key: employee-sku
rhn_pool_ids:
  # physical
  #- 99999999999999999999999999999999
  # virtual
  - 88888888888888888888888888888888
----
====

== Setup

* link:setup-pyenv[] creates a virtualenv to satisfy depts for Ansible https://docs.ansible.com/ansible/latest/modules/vmware_guest_module.html[vmware_guest] module like https://pypi.org/project/pyvmomi/[PyVmomi]
* link:requirements.yml[] includes some helpful roles from https://galaxy.ansible.com/[Ansible Galaxy] like https://galaxy.ansible.com/redhatinsights/insights-client[insights-client]

== Playbooks

* link:mkhelper.yml[] - Playbook to build VMware VM and prep OS for munging by https://github.com/RedHatOfficial/ocp4-helpernode[RedHatOfficial / ocp4-helpernode] Playbook prior to contributing back to same
* link:infra.yml[] - Playbook for a persistent Infrastructure host with a fancy Squid MITM explite and transparent proxy.
* link:rhpds-bastion.yml[] - Prep a Red Hat Product Demo System bastion host for use.

== Roles

* link:roles/dhcpd/[] - Configure lab dhcpd server
* link:roles/pxe/[] - Configure lab PXE server
* link:roles/ocp3/[] - Configure ocp3 lab starting with the link:roles/ocp3/tasks/bastion.yml[]

== OpenShift

See https://gitlab.com/dlbewley/openshift-practice/[openshift-practice repo]

=== Lab DNS Setup

For each cluster add DNS records for VIPs needed by vSphere IPI install method.
See also link:roles/dhcpd/[]

* Edit dynamic DNS zone by freezing it

[source,bash]
----
$ ssh root@infra
$ cd /var/named/chroot
$ rndc -k etc/rndc.key freeze lab.bewley.net
$ rndc -k etc/rndc.key freeze 5.168.192.in-addr.arpa
----

* Add `A` for VIPs in top level zone and use `CNAME`s for cluster domain names.

./var/named/chroot/var/named/internal/db.lab.bewley.net
[source,bash]
----
$ORIGIN lab.bewley.net.
vtprxy-lb-api           A       192.168.5.13
vtprxy-lb-apps          A       192.168.5.12
$ORIGIN vtprxy.lab.bewley.net.
api                     CNAME   vtprxy-lb-api.lab.bewley.net.
$ORIGIN apps.vtprxy.lab.bewley.net.
*                       CNAME   vtprxy-lb-apps.lab.bewley.net.
----

./var/named/chroot/var/named/internal/db.192.168.5.in-addr.arpa
[source,bash]
----
$ORIGIN 5.168.192.in-addr.arpa.
1                       PTR     gw.lab.bewley.net.
2                       PTR     infra.lab.bewley.net.
12                      PTR     vtprxy-lb-apps.lab.bewley.net.
13                      PTR     vtprxy-lb-api.lab.bewley.net.
----

* Thaw zones and check results for errors

[source,bash]
----
$ rndc -k etc/rndc.key unfreeze lab.bewley.net
$ rndc -k etc/rndc.key unfreeze 5.168.192.in-addr.arpa
$ systemctl status named-chroot
$ host vtprxy-lb-api.lab.bewley.net
vtprxy-lb-api.lab.bewley.net has address 192.168.5.13
$ host 192.168.5.13
13.5.168.192.in-addr.arpa domain name pointer vtprxy-lb-api.lab.bewley.net.
----
